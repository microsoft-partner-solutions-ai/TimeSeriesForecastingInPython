{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core import Workspace, Experiment, Run, ScriptRunConfig, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "import json\n",
    "import os\n",
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "#from sklearn.externals import joblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: ShivaMLservice\n",
      "Azure region: westus2\n",
      "Subscription id: 46668180-b0ad-4a49-bed9-88f16f315dce\n",
      "Resource group: MLGroup\n"
     ]
    }
   ],
   "source": [
    "#Service Principal Authentication\n",
    "\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "import os\n",
    "\n",
    "base_dir='./../configuration'\n",
    "config_json = os.path.join(base_dir, \"config.json\")\n",
    "with open(config_json, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "workspace_name = config[\"workspace_name\"]\n",
    "resource_group = config[\"resource_group\"]\n",
    "subscription_id = config[\"subscription_id\"]\n",
    "location = config[\"location\"]\n",
    "    \n",
    "auth = ServicePrincipalAuthentication(\n",
    "    tenant_id=config[\"tenant_id\"],\n",
    "    service_principal_id=config[\"service_principal_id\"],\n",
    "    service_principal_password=config[\"service_principal_password\"],\n",
    ")\n",
    "\n",
    "ws = Workspace.get(\n",
    "        name=workspace_name,\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group=resource_group,        \n",
    "        auth=auth\n",
    "    )\n",
    "\n",
    "print('Workspace name: ' + ws.name, 'Azure region: ' + ws.location, 'Subscription id: ' + ws.subscription_id,'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code B6DQF7WLC to authenticate.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(workspace=ws, name='transaction_ts2013')\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach Experiment\n",
    "experiment_name = \"arima-localrun\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "print(exp.name, exp.workspace.name, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing a run configuration property on-fly.\n",
    "run_config_user_managed = RunConfiguration()\n",
    "run_config_user_managed.environment.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import os\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import json\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "from pandas import Grouper\n",
      "#from pandas.plotting import lag_plot\n",
      "#from pandas.plotting import autocorrelation_plot\n",
      "from statsmodels.graphics.tsaplots import plot_acf\n",
      "from statsmodels.graphics.tsaplots import plot_pacf\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.metrics import r2_score\n",
      "#from statsmodels.tsa.seasonal import seasonal_decompose\n",
      "from statsmodels.tsa.stattools import adfuller\n",
      "#from sklearn.model_selection import TimeSeriesSplit\n",
      "#from statsmodels.graphics.gofplots import qqplot\n",
      "#from statsmodels.tsa.ar_model import AR\n",
      "from statsmodels.tsa.arima_model import ARIMA\n",
      "\n",
      "from azureml.core import Dataset, Run\n",
      "\n",
      "run = Run.get_context()\n",
      "# get input dataset by name\n",
      "#dataset = run.input_datasets['transaction_ts']\n",
      "\n",
      "ws = run.experiment.workspace\n",
      "dataset = Dataset.get_by_name(workspace=ws, name='transaction_ts')\n",
      "\n",
      "df = dataset.to_pandas_dataframe()\n",
      "df.set_index('TransactionDate',inplace=True)\n",
      "df.columns = ['PaidAmount']\n",
      "series = pd.Series(df['PaidAmount'])\n",
      "\n",
      "def mean_and_variance(X):\n",
      "    split = int(len(X) / 2)\n",
      "    X1, X2 = X[0:split], X[split:]\n",
      "    mean1, mean2 = X1.mean(), X2.mean()\n",
      "    var1, var2 = X1.var(), X2.var()\n",
      "    print('mean1=%f, mean2=%f' % (mean1, mean2))\n",
      "    print('variance1=%f, variance2=%f' % (var1, var2))\n",
      "    \n",
      "mean_and_variance(series.values)\n",
      "\n",
      "def fuller_test(X):\n",
      "    result = adfuller(X)\n",
      "    print('ADF Statistic: %f' % result[0])\n",
      "    print('p-value: %f' % result[1])\n",
      "    print('Critical Values:')\n",
      "    for key, value in result[4].items():\n",
      "    \tprint('\\t%s: %.3f' % (key, value))\n",
      "        \n",
      "fuller_test(series.values)\n",
      "\n",
      "plot_acf(series)\n",
      "\n",
      "plot_pacf(series)\n",
      "\n",
      "X = series.values\n",
      "size = int(len(X) * 0.8)\n",
      "train, test = X[0:size], X[size:len(X)]\n",
      "\n",
      "model = ARIMA(train, order=(2,0,2))\n",
      "model_fit = model.fit(disp=0)\n",
      "print(model_fit.summary())\n",
      "\n",
      "# plot residual errors\n",
      "residuals = pd.DataFrame(model_fit.resid)\n",
      "residuals.plot()\n",
      "plt.show()\n",
      "residuals.plot(kind='kde')\n",
      "plt.show()\n",
      "print(residuals.describe())\n",
      "\n",
      "predictions=model_fit.forecast(steps=test.size)[0]\n",
      "\n",
      "mse = mean_squared_error(test, predictions)\n",
      "rmse = np.sqrt(mse)\n",
      "r2 = r2_score(test,predictions)\n",
      "print('Test RMSE: %.3f' % rmse)\n",
      "print('Test R2: %.3f' % r2)\n",
      "\n",
      "# plot\n",
      "plt.plot(test)\n",
      "plt.plot(predictions, color='red')\n",
      "plt.show()\n",
      "\n",
      "run.log('RMSE', rmse)\n",
      "run.log('R2', r2)\n",
      "\n",
      "model_file_name = 'arima_notebook_model.pkl'\n",
      "\n",
      "os.makedirs('./outputs', exist_ok=True)\n",
      "with open(model_file_name, 'wb') as file:\n",
      "    joblib.dump(value=model_fit, filename='outputs/' + model_file_name)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./scripts/training/transactions_arima.py', 'r') as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting an experiment.\n"
     ]
    }
   ],
   "source": [
    "print(\"Submitting an experiment.\")\n",
    "\n",
    "#script_arguments = [dataset.as_named_input('robberies')]\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=\"./scripts\",\n",
    "    script=\"training/transactions_arima.py\",\n",
    "    run_config=run_config_user_managed,\n",
    ")\n",
    "run = exp.submit(src)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: arima-localrun_1593473429_7dbcf5bc\n",
      "Web View: https://ml.azure.com/experiments/arima-localrun/runs/arima-localrun_1593473429_7dbcf5bc?wsid=/subscriptions/46668180-b0ad-4a49-bed9-88f16f315dce/resourcegroups/MLGroup/workspaces/ShivaMLservice\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Entering context manager injector. Current time:2020-06-29T23:30:35.594496\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 2677\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ training/transactions_arima.py ] with arguments: []\n",
      "After variable expansion, calling script [ training/transactions_arima.py ] with arguments: []\n",
      "\n",
      "mean1=631.557791, mean2=729.614038\n",
      "variance1=231436.602522, variance2=186484.007120\n",
      "ADF Statistic: -2.910140\n",
      "p-value: 0.044181\n",
      "Critical Values:\n",
      "\t1%: -3.453\n",
      "\t5%: -2.872\n",
      "\t10%: -2.572\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1283: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return rho, np.sqrt(sigmasq)\n",
      "                              ARMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  244\n",
      "Model:                     ARMA(2, 2)   Log Likelihood               -1825.477\n",
      "Method:                       css-mle   S.D. of innovations            428.155\n",
      "Date:                Mon, 29 Jun 2020   AIC                           3662.954\n",
      "Time:                        23:31:16   BIC                           3683.937\n",
      "Sample:                             0   HQIC                          3671.405\n",
      "                                                                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        665.9043     25.419     26.197      0.000     616.084     715.725\n",
      "ar.L1.y        1.2393      0.017     71.048      0.000       1.205       1.273\n",
      "ar.L2.y       -0.9818      0.021    -46.266      0.000      -1.023      -0.940\n",
      "ma.L1.y       -1.2156      0.034    -36.218      0.000      -1.281      -1.150\n",
      "ma.L2.y        0.9038      0.053     17.145      0.000       0.800       1.007\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            0.6311           -0.7875j            1.0092           -0.1425\n",
      "AR.2            0.6311           +0.7875j            1.0092            0.1425\n",
      "MA.1            0.6725           -0.8088j            1.0519           -0.1396\n",
      "MA.2            0.6725           +0.8088j            1.0519            0.1396\n",
      "-----------------------------------------------------------------------------\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "                 0\n",
      "count   244.000000\n",
      "mean     -0.096600\n",
      "std     430.663891\n",
      "min    -744.788906\n",
      "25%    -340.239341\n",
      "50%     -94.398466\n",
      "75%     313.439670\n",
      "max    1170.483843\n",
      "Test RMSE: 391.245\n",
      "Test R2: 0.188\n",
      "Figure(640x480)\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 2677\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.0012471675872802734 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: arima-localrun_1593473429_7dbcf5bc\n",
      "Web View: https://ml.azure.com/experiments/arima-localrun/runs/arima-localrun_1593473429_7dbcf5bc?wsid=/subscriptions/46668180-b0ad-4a49-bed9-88f16f315dce/resourcegroups/MLGroup/workspaces/ShivaMLservice\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'arima-localrun_1593473429_7dbcf5bc',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-06-29T23:30:34.06339Z',\n",
       " 'endTimeUtc': '2020-06-29T23:31:28.553682Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '9830ff7a-9269-44ba-93f1-faf714c926ca',\n",
       "  'azureml.git.repository_uri': 'git@github.com:us-ocp-ai/TimeSeriesForecastingInPython.git',\n",
       "  'mlflow.source.git.repoURL': 'git@github.com:us-ocp-ai/TimeSeriesForecastingInPython.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'ba2e73064099f7b2c08608afc0bf05917b5ab6c8',\n",
       "  'mlflow.source.git.commit': 'ba2e73064099f7b2c08608afc0bf05917b5ab6c8',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': '88ea0f06-10e0-4e7f-8679-bb40b535886a'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'runDefinition': {'script': 'training/transactions_arima.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment arima-localrun Environment',\n",
       "   'version': 'Autosave_2020-06-29T21:24:17Z_e697c19d',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'project_environment'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://shivamlservice2731961382.blob.core.windows.net/azureml/ExperimentRun/dcid.arima-localrun_1593473429_7dbcf5bc/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=dNkp%2BpRkYumXX%2BdBsqJY8h7TEAAY3PRZC8%2BJL2%2FqLJw%3D&st=2020-06-29T23%3A21%3A31Z&se=2020-06-30T07%3A31%3A31Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://shivamlservice2731961382.blob.core.windows.net/azureml/ExperimentRun/dcid.arima-localrun_1593473429_7dbcf5bc/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=O9WrPC7Pge%2FyuFfJ3WFpDkBAIHGjmPFiaxXbRzfD%2Bks%3D&st=2020-06-29T23%3A21%3A31Z&se=2020-06-30T07%3A31%3A31Z&sp=r',\n",
       "  'logs/azureml/2677_azureml.log': 'https://shivamlservice2731961382.blob.core.windows.net/azureml/ExperimentRun/dcid.arima-localrun_1593473429_7dbcf5bc/logs/azureml/2677_azureml.log?sv=2019-02-02&sr=b&sig=4G59HzwgwaoJ2VFl2w7X4ThNKEsxfm7RLFwz%2F9LZzJA%3D&st=2020-06-29T23%3A21%3A31Z&se=2020-06-30T07%3A31%3A31Z&sp=r'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows output of the run on stdout.\n",
    "run.wait_for_completion(show_output=True, wait_post_processing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise exception if run fails\n",
    "if run.get_status() == \"Failed\":\n",
    "    raise Exception(\n",
    "        \"Training on local failed with following run status: {} and logs: \\n {}\".format(\n",
    "            run.get_status(), run.get_details_with_logs()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = {}\n",
    "run_id[\"run_id\"] = run.id\n",
    "run_id[\"experiment_name\"] = run.experiment.name\n",
    "with open(\"./configuration/run_id.json\", \"w\") as outfile:\n",
    "    json.dump(run_id, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID for last run: arima-localrun_1593473429_7dbcf5bc\n"
     ]
    }
   ],
   "source": [
    "# Get the latest evaluation result\n",
    "try:\n",
    "    with open(\"./configuration/run_id.json\") as f:\n",
    "        config = json.load(f)\n",
    "    if not config[\"run_id\"]:\n",
    "        raise Exception(\"No new model to register as production model perform better\")\n",
    "except:\n",
    "    print(\"No new model to register as production model perform better\")\n",
    "    # raise Exception('No new model to register as production model perform better')\n",
    "    sys.exit(0)\n",
    "\n",
    "run_id = config[\"run_id\"]\n",
    "experiment_name = config[\"experiment_name\"]\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "run = Run(experiment=exp, run_id=run_id)\n",
    "names = run.get_file_names\n",
    "names()\n",
    "print(\"Run ID for last run: {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model arima_notebook_model.pkl to Project root directory\n"
     ]
    }
   ],
   "source": [
    "model_local_dir = \"model\"\n",
    "os.makedirs(model_local_dir, exist_ok=True)\n",
    "\n",
    "# Download Model to Project root directory\n",
    "model_name = \"arima_notebook_model.pkl\"\n",
    "run.download_file(\n",
    "    name=\"./outputs/\" + model_name, output_file_path=\"./model/\" + model_name\n",
    ")\n",
    "print(\"Downloaded model {} to Project root directory\".format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model arima_notebook_model.pkl\n",
      "Model registered: arima_notebook_model.pkl \n",
      "Model Description: Time series forecasting model for Boston robberies dataset \n",
      "Model Version: 2\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"./model\")\n",
    "model = Model.register(\n",
    "    model_path=model_name,  # this points to a local file\n",
    "    model_name=model_name,  # this is the name the model is registered as\n",
    "    tags={\"area\": \"AW Forecasting\", \"type\": \"forecasting\", \"run_id\": run_id},\n",
    "    description=\"Time series forecasting model for Boston robberies dataset\",\n",
    "    workspace=ws,\n",
    ")\n",
    "os.chdir(\"..\")\n",
    "print(\n",
    "    \"Model registered: {} \\nModel Description: {} \\nModel Version: {}\".format(\n",
    "        model.name, model.description, model.version\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the registered model details to /aml_config/model.json\n",
    "model_json = {}\n",
    "model_json[\"model_name\"] = model.name\n",
    "model_json[\"model_version\"] = model.version\n",
    "model_json[\"run_id\"] = run_id\n",
    "with open(\"./configuration/model.json\", \"w\") as outfile:\n",
    "    json.dump(model_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='ShivaMLservice', subscription_id='46668180-b0ad-4a49-bed9-88f16f315dce', resource_group='MLGroup'), name=arima_notebook_model.pkl, id=arima_notebook_model.pkl:2, version=2, tags={'area': 'AW Forecasting', 'type': 'forecasting', 'run_id': 'arima-localrun_1593473429_7dbcf5bc'}, properties={})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "from azureml.core.model import Model\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    from sklearn.externals import joblib\n",
    "\n",
    "    # load the model from file into a global object\n",
    "    model_path = Model.get_model_path(model_name=\"./model/arima_notebook_model.pkl\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)[\"data\"]\n",
    "        data = numpy.array(data)\n",
    "        result=model.forecast(steps=data[0])[0]\n",
    "        return json.dumps({\"result\": result.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result:  {\"result\": [796.5203792789346, 916.3628259630898, 848.0511918532666]}\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "step_size = [3]\n",
    "test_sample = json.dumps({\"data\": step_size})\n",
    "test_sample = bytes(test_sample, encoding=\"utf8\")\n",
    "prediction = run(raw_data=test_sample)\n",
    "print(\"Test result: \", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
